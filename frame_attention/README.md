## Table of Contents
- [How to Run the Code](#how-to-run-the-code)
- [Project Structure](#project-structure)
- [Dependencies](#dependencies)
- [Notes](#notes)

## How to Run the Code

You have two options to run the object tracking code:

1. **Run Directly from an IDE**  
   Open the script in your IDE, navigate to line 11, and modify the `video_path` to point to your desired video file. Then, simply run the script.

2. **Run from Command Line**  
   Open a terminal or command prompt and use the following command:
   ```bash
   python your_script.py --video_path path/to/your/video.mp4

## Project Structure

The repository contains the following directories and files:

- **`fine-tune/`**  
  Contains code and resources for fine-tuning and retraining the YOLO model for specific object detection tasks.
  - **`dataset/`**: Contains the dataset used for model training.
  - **`frames_with_detections/`**: Stores extracted frames from videos where objects were detected.
  - **`runs/`**: Contains model weights and other training logs.
  - **`data.yaml`**: Configuration file specifying model parameters and paths.
  - **`get_dataset/`**: Script for extracting frames and generating bounding box annotations and labels.
  - **`split-finetune_data/`**: Script for splitting the data into training and validation sets with an 80-20 ratio.
  - **`run_finetune/`**: Script to initiate model training or fine-tuning. For optimal performance, it is recommended to:
    - Set up a new project directory with this folder only.
    - Install a CUDA-compatible version of PyTorch in a virtual environment.
    - Adjust the `device` parameter to match the desired GPU or CPU ID based on hardware availability.

- **`models/`**  
  Directory for models currently used, tested, or under development.

- **`track_output/`**  
  Stores the output files generated by the tracking process, including:
  - Processed video with bounding boxes around tracked objects.
  - Excel log file with object count and timestamp data.

- **`videos/`**  
  Contains the video files intended for tracking.

- **`sort/`**  
  Contains the implementation of the SORT (Simple Online and Realtime Tracking) algorithm used for tracking detected objects across frames.

- **`temp/`**  
  Temporary testing area for running object tracking on a single video.

- **`test/`**  
  Similar to `temp/`, but without using SORT for tracking.

- **`tracker/`**  
  Main logic for object tracking. This module processes the video, applies the YOLO model for object detection, and saves the output video and Excel log file.

- **`utils/`**
  We have here some functions that we used for some experiments:
1. counter - Counts the squences in a file with focus on different ID's only
2. generator - Extracts frames from a vide and saves them in a folder
3. mergervid - Merges videos from a folder into a single video using nvidia codec and ffmeg for faster processing


- **`requirements/`**  
  Libs required for the project.

## Dependencies

The project dependencies are listed in the `requirements.txt` file. You can install them using the following command:

```bash
pip install -r requirements.txt
```
We used Python 3.11 for this project.

## Notes
Code is explained in files and have some examples. If any other questions feel free to contact us or raise an issue. Thank you!